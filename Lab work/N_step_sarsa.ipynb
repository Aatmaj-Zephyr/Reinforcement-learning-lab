{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aDTzLuSiXTuz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "grid_height = 4\n",
        "grid_length = 3\n",
        "wind_intensity = [0,0,0,0,0,0,0,0,0,0]\n",
        "possible_actions = [(1,0),(0,1),(0,-1),(-1,0)] #right, up, down\n",
        "start = (0,0)\n",
        "goal = (2,3)\n",
        "action_matrix= []\n",
        "\n",
        "\n",
        "for state_x in range(grid_length):\n",
        "    action_matrix.append([])\n",
        "    for state_y in range(grid_height):\n",
        "      action_matrix[state_x].append([])\n",
        "      for action_num in range(len(possible_actions)):\n",
        "        init_prob = 100\n",
        "\n",
        "        action_matrix[state_x][state_y].append(init_prob)\n",
        "action_matrix = np.array(action_matrix,dtype=np.float64)\n",
        "# print(action_matrix)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "current_state = start\n",
        "\n",
        "n = 3  # Define n-step\n",
        "gamma = 0.99\n",
        "\n",
        "for k in range(10000):\n",
        "    current_state = (random.randint(0, grid_length - 1), random.randint(0, grid_height - 1))\n",
        "\n",
        "    for i in range(1000):\n",
        "        # Initialize the reward sequence and state-action trajectory\n",
        "        rewards = []\n",
        "        state_action_sequence = [(current_state, None)]  # Store state and action\n",
        "\n",
        "        for step in range(n):\n",
        "            action = random.choices(possible_actions, weights=action_matrix[current_state[0]][current_state[1]])[0]\n",
        "            action_index = possible_actions.index(action)\n",
        "\n",
        "            # Take the action and determine the new state\n",
        "            x_move = max(min(current_state[0] + action[0], grid_length - 1), 0)\n",
        "            y_move = max(min(current_state[1] + action[1] + wind_intensity[x_move], grid_height - 1), 0)\n",
        "            new_state = (x_move, y_move)\n",
        "\n",
        "            # Store the state and action\n",
        "            state_action_sequence.append((new_state, action_index))\n",
        "\n",
        "            # Check for terminal state or penalty\n",
        "            if new_state[0] == 3 and new_state[1] == 2:\n",
        "                reward = -10\n",
        "                rewards.append(reward)\n",
        "                break  # Exit the n-step loop early if terminal state reached\n",
        "\n",
        "            # Compute the reward for the current step\n",
        "            reward = -0.01 * ((x_move - goal[1] - 1) ** 2 + (y_move - goal[0]) ** 2)\n",
        "            rewards.append(reward)\n",
        "\n",
        "            current_state = new_state\n",
        "\n",
        "        # After `n` steps, update the Q-values\n",
        "        for t in range(len(rewards)):  # Iterate over the rewards we collected\n",
        "            G = sum([gamma ** i * rewards[i] for i in range(t, len(rewards))])  # Discounted sum of rewards\n",
        "            current_state, action_index = state_action_sequence[t]\n",
        "            if action_index is not None:\n",
        "                next_state, next_action_index = state_action_sequence[t + 1]\n",
        "                next_x, next_y = next_state\n",
        "                action_matrix[current_state[0]][current_state[1]][action_index] += 0.001 * (\n",
        "                    G + gamma * action_matrix[next_x][next_y][next_action_index] -\n",
        "                    action_matrix[current_state[0]][current_state[1]][action_index]\n",
        "                )\n",
        "                action_matrix[current_state[0]][current_state[1]][action_index] = max(\n",
        "                    action_matrix[current_state[0]][current_state[1]][action_index], 0.00001\n",
        "                )\n",
        "\n"
      ],
      "metadata": {
        "id": "AfhdyDmkZfn-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "965977ad-3643-410b-e4a6-fc2ac61e42ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-697b8b5f9621>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossible_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maction_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurrent_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurrent_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0maction_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpossible_actions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "action_matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cgzWfMxUceDL",
        "outputId": "3f543c99-0326-4a09-b5e8-b103890bf7e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[100.        , 100.        ,  60.85322282,  60.867984  ],\n",
              "        [100.        ,  60.93531981,  60.98863785,  60.16956956],\n",
              "        [100.        ,  60.99048395,  61.04076497,  60.27916385],\n",
              "        [100.        ,  60.94655259, 100.        ,  60.96162312]],\n",
              "\n",
              "       [[ 61.04456245, 100.        ,  60.29659308,  61.06709076],\n",
              "        [ 60.28768893,  60.34078407,  60.30563652,  60.30002473],\n",
              "        [ 60.41002324,  60.40272181,  60.39677207,  60.40773539],\n",
              "        [ 61.15318535,  60.41374221, 100.        ,  61.16283621]],\n",
              "\n",
              "       [[ 61.14338619, 100.        ,  61.12781446, 100.        ],\n",
              "        [ 60.45402063,  61.20821216,  61.28134291, 100.        ],\n",
              "        [ 60.58432214,  61.34003091,  61.39023598, 100.        ],\n",
              "        [ 61.32224908,  61.3193657 , 100.        , 100.        ]]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_actions = []\n",
        "for x in range(grid_length):\n",
        "  best_actions.append([])\n",
        "  for y in range(grid_height):\n",
        "    a = np.argmax(action_matrix[x][y])\n",
        "    if( a==0):\n",
        "      best_actions[x].append(\">\")\n",
        "    elif(a==1):\n",
        "      best_actions[x].append(\"^\")\n",
        "    else:\n",
        "      best_actions[x].append(\"v\")\n",
        "best_actions = np.array(best_actions)\n",
        "print(best_actions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5PpX9MJjdPCK",
        "outputId": "4ebb2088-11d4-4ae6-faf0-4838edc7e539"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['>' '>' '>' '>']\n",
            " ['^' '^' '>' 'v']\n",
            " ['^' 'v' 'v' 'v']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for x in range(grid_length):\n",
        "  for y in range(grid_height):\n",
        "\n",
        "    print(-0.01*((x-goal[1]-1)**2+(y-goal[0])**2),end=\";\")\n",
        "  print()"
      ],
      "metadata": {
        "id": "phK97bHnwGXn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d257f890-b7eb-46aa-ea37-bf5608485cd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.2;-0.17;-0.16;-0.17;\n",
            "-0.13;-0.1;-0.09;-0.1;\n",
            "-0.08;-0.05;-0.04;-0.05;\n"
          ]
        }
      ]
    }
  ]
}